{
  "lora_weights": {
    "weight_a": "simulated_lora_weight_a",
    "weight_b": "simulated_lora_weight_b",
    "alpha": 16,
    "rank": 8
  },
  "base_model": "mlx-community/Llama-2-7B-4bit",
  "training_data": 300
}